{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "/anaconda3/lib/python3.7/site-packages/jpype/_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "twitter = Twitter()\n",
    "from collections import namedtuple\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "#import Early Stopping\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec.load('slang_word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>dict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>새끼</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>남자</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>진짜</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>여자</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>사람</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  frequency  dict  class\n",
       "0   새끼         64     1      1\n",
       "1   남자         37     1      0\n",
       "2   진짜         36     1      0\n",
       "3   여자         32     1      0\n",
       "4   사람         27     1      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"/Users/SAEROM/slang_dict_twitter(1).csv\", encoding='cp949')\n",
    "#첫 5행을 불러옴\n",
    "dataset.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 160 200\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.2, shuffle = True)\n",
    "train, valid = train_test_split(train, test_size=0.2, shuffle = True)\n",
    "print(len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        #self.data=[]\n",
    "        #self.label=[]\n",
    "        \n",
    "        #word,freq,dict,tag라는 라벨을 갖고 있는 namedtuple 클래스를 생성.\n",
    "        TaggedWord = namedtuple('TaggedWord', 'word freq dict tag')\n",
    "        tagged_words = [TaggedWord(w, f, d, c) for w,f,d,c \n",
    "                              in data[[\"word\", \"frequency\", \"dict\", \"class\"]].values]\n",
    "        #print(tagged_words)\n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        \n",
    "        vector_=[]\n",
    "        for t in tagged_words:\n",
    "            if t.word in w2v_model: \n",
    "                vector_ = []\n",
    "                vector = w2v_model.wv[t.word]\n",
    "                #vector_.append(vector)\n",
    "                #vector_.append(t.freq)\n",
    "                #vector_.append(t.dict)\n",
    "                for v in vector:\n",
    "                    vector_.append(v)\n",
    "                vector_.append(t.freq)\n",
    "                vector_.append(t.dict)\n",
    "            \n",
    "        \n",
    "            data_x.append(vector_)\n",
    "            data_y.append(t.tag)\n",
    "        #print(data_x)\n",
    "        #print(data_y)\n",
    "\n",
    "        #print(type(np.array(data_x)))\n",
    "        #np.array(data_y)\n",
    "        \n",
    "        self.data = np.array(data_x)\n",
    "        self.label = np.array(data_y)\n",
    "        \n",
    "        print(\"<데이터의 shape>\")\n",
    "        print(type(self.data))\n",
    "        print(np.array(self.data).shape)\n",
    "        print(\"<데이터 내용>\") \n",
    "        print(torch.tensor(self.data[0], dtype=torch.float))\n",
    "        print(\"<레이블 표시>\") \n",
    "        print(self.label[0])\n",
    "        print(\"<총 레이블 길이>\") \n",
    "        print(len(self.label)) \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.data[index], dtype=torch.float), self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN(\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=102, out_features=64, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=2, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DNN (nn.Module):\n",
    "    def __init__(self):\n",
    "        super (DNN, self).__init__ ()\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear (102,64),\n",
    "            nn.ELU())\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear (64, 32),\n",
    "            nn.ELU())\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear (32, 2),\n",
    "            nn.ELU())\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view (-1, 102)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "model = DNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model (model, batch_size, patience, epochs): \n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    ##################################################\n",
    "    #train and validate model#\n",
    "    ##################################################\n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "  \n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################  \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "        \n",
    "    for epoch in range(1, epochs+1):\n",
    "        for batch, (data, label) in enumerate (loader_train, 1):\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, label)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # record training loss\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "    ###################\n",
    "    # validate the model #\n",
    "    ###################  \n",
    "        model.eval()\n",
    "        for data, label in loader_valid:\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, label)\n",
    "            # record validation loss\n",
    "            valid_losses.append(loss.item())\n",
    "    \n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        \n",
    "        epoch_len = len(str(epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "            \n",
    "    return  model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<데이터의 shape>\n",
      "<class 'numpy.ndarray'>\n",
      "(640, 102)\n",
      "<데이터 내용>\n",
      "tensor([ 0.3819,  0.2132, -0.3604,  0.2379, -0.1995,  0.3333,  0.0216, -0.7131,\n",
      "        -0.3337,  0.8733, -0.0238, -0.5600,  0.0390,  0.3155, -0.3521, -0.4481,\n",
      "         0.3581, -0.0848, -0.2443, -0.5533,  0.7288,  0.1514, -0.3361, -0.1244,\n",
      "         0.4870, -0.1097,  0.2365, -0.4217, -0.4788, -0.1319,  0.6424,  0.3803,\n",
      "         0.2332,  0.4452, -0.2730,  0.2229,  0.1602, -0.2200,  1.0953,  0.9725,\n",
      "        -0.2804, -0.4278, -1.0465, -0.1070,  0.3589, -0.5911, -0.1063,  0.1173,\n",
      "        -0.1100,  0.0822, -0.1169, -0.9469,  0.1719, -0.3450, -0.0824, -1.0463,\n",
      "        -0.4829,  0.6174, -0.2881,  0.6837,  0.2494, -0.0600, -0.0855, -0.7763,\n",
      "        -0.2366,  0.0754,  0.2075,  0.0589,  0.5708,  0.3120, -0.5714, -0.0172,\n",
      "         0.5878,  0.1189,  0.4924,  0.6758,  0.0679, -0.2885,  0.6142, -0.3036,\n",
      "         0.1036, -0.9548,  0.3040, -0.2315, -0.7264, -0.6967,  0.4627,  0.1315,\n",
      "         0.2449,  0.2645,  0.5762,  0.4029,  0.0325,  0.2728,  0.6840, -0.1429,\n",
      "         0.1690,  0.2064, -0.5054,  0.3322,  2.0000,  0.0000])\n",
      "<레이블 표시>\n",
      "1\n",
      "<총 레이블 길이>\n",
      "640\n",
      "<데이터의 shape>\n",
      "<class 'numpy.ndarray'>\n",
      "(200, 102)\n",
      "<데이터 내용>\n",
      "tensor([-0.3199,  0.0274, -0.3871, -0.2702,  0.2122,  0.3530,  0.2151,  0.6726,\n",
      "         0.5091, -0.3027,  0.3002,  0.3709, -0.6838,  0.0215, -0.1874,  0.2612,\n",
      "         0.0921, -0.4882, -0.2132,  0.0779,  0.5598,  0.2632, -0.0526, -0.6302,\n",
      "        -0.1598,  0.0502, -0.1785, -0.2343, -0.3280, -0.1010,  0.2161,  0.5143,\n",
      "         0.4125,  0.3298,  0.0762, -0.1027,  0.3079,  0.4262,  0.3481,  0.4348,\n",
      "        -0.0703,  0.0095, -0.2797,  0.7232,  0.6300, -0.7475, -0.0970, -0.1415,\n",
      "        -0.1538,  0.4638, -0.0238, -0.3198, -0.3531,  0.3298,  0.1701, -0.0556,\n",
      "        -0.5155,  0.3464, -0.1463, -0.2896, -0.1711, -0.1677, -0.3449, -0.1734,\n",
      "         0.1150, -0.0303,  0.1445,  0.0924, -0.0563,  0.4640, -0.0839, -0.6329,\n",
      "         0.1332, -0.0021,  0.0074, -0.3107,  0.4055,  0.0528,  1.0035, -0.0714,\n",
      "         0.0104, -0.2903, -0.1391, -0.0967, -0.7534,  0.1599,  0.1042, -0.2630,\n",
      "         0.5450,  0.2589,  0.3430,  0.0908, -0.1966, -0.3964,  0.1265,  0.0316,\n",
      "        -0.0121,  0.4815, -0.2562,  0.2444,  1.0000,  0.0000])\n",
      "<레이블 표시>\n",
      "1\n",
      "<총 레이블 길이>\n",
      "200\n",
      "<데이터의 shape>\n",
      "<class 'numpy.ndarray'>\n",
      "(160, 102)\n",
      "<데이터 내용>\n",
      "tensor([-0.5361,  0.7485, -0.4460, -0.4374, -0.1759,  0.4422,  0.0134, -0.2140,\n",
      "        -0.1926,  0.2819, -0.5068, -0.0743,  0.0977, -0.1159, -0.1218, -0.5959,\n",
      "         0.1917, -0.2069,  0.0107, -0.0575,  0.3746,  0.5977, -0.0217, -0.6360,\n",
      "         0.2858,  0.1665, -0.3530,  0.4740, -0.2797, -0.1253,  0.3226,  0.5160,\n",
      "         0.7431,  0.6229,  0.0602,  0.1808,  0.2887, -0.1442,  0.4823, -0.2381,\n",
      "         0.0644, -0.2753, -0.1642, -0.0047,  0.3401, -0.2671,  0.0424, -0.3296,\n",
      "        -0.2671,  0.1011, -0.5453, -0.3417, -0.2710, -0.5582,  0.7469, -1.1951,\n",
      "        -0.6059,  0.2395, -0.0932,  0.0428,  0.0269,  0.0327, -0.1948, -0.7355,\n",
      "        -0.0171, -0.5985,  0.0669,  0.1018,  0.5494,  0.0627,  0.1232, -0.3062,\n",
      "         0.3884, -0.4372,  0.3166,  0.1484,  0.4171,  0.2745,  0.2889, -0.5534,\n",
      "         0.2723,  0.3386,  0.0453,  0.2512, -1.0379,  0.3116,  0.5926, -1.0072,\n",
      "        -0.2916,  0.1465,  0.5033,  0.3881, -0.1452, -0.1986, -0.0169, -0.1087,\n",
      "         0.2498,  0.1453, -0.4206,  0.4135,  1.0000,  1.0000])\n",
      "<레이블 표시>\n",
      "0\n",
      "<총 레이블 길이>\n",
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "data_train = Data (data = train)\n",
    "loader_train = torch.utils.data.DataLoader(data_train, batch_size = 20, shuffle = False)\n",
    "data_test = Data (data = test)\n",
    "loader_test = torch.utils.data.DataLoader(data_test, batch_size = 20, shuffle = False)\n",
    "data_valid = Data (data = valid)\n",
    "loader_valid = torch.utils.data.DataLoader(data_valid, batch_size = 20, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/100] train_loss: 0.59670 valid_loss: 0.52766\n",
      "Validation loss decreased (inf --> 0.527665).  Saving model ...\n",
      "[  2/100] train_loss: 0.52789 valid_loss: 0.51109\n",
      "Validation loss decreased (0.527665 --> 0.511095).  Saving model ...\n",
      "[  3/100] train_loss: 0.52310 valid_loss: 0.50925\n",
      "Validation loss decreased (0.511095 --> 0.509252).  Saving model ...\n",
      "[  4/100] train_loss: 0.52205 valid_loss: 0.50858\n",
      "Validation loss decreased (0.509252 --> 0.508583).  Saving model ...\n",
      "[  5/100] train_loss: 0.52087 valid_loss: 0.50814\n",
      "Validation loss decreased (0.508583 --> 0.508139).  Saving model ...\n",
      "[  6/100] train_loss: 0.51599 valid_loss: 0.50808\n",
      "Validation loss decreased (0.508139 --> 0.508081).  Saving model ...\n",
      "[  7/100] train_loss: 0.50214 valid_loss: 0.50187\n",
      "Validation loss decreased (0.508081 --> 0.501873).  Saving model ...\n",
      "[  8/100] train_loss: 0.49221 valid_loss: 0.49819\n",
      "Validation loss decreased (0.501873 --> 0.498186).  Saving model ...\n",
      "[  9/100] train_loss: 0.48274 valid_loss: 0.49644\n",
      "Validation loss decreased (0.498186 --> 0.496442).  Saving model ...\n",
      "[ 10/100] train_loss: 0.47221 valid_loss: 0.49822\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 11/100] train_loss: 0.46052 valid_loss: 0.49606\n",
      "Validation loss decreased (0.496442 --> 0.496056).  Saving model ...\n",
      "[ 12/100] train_loss: 0.44996 valid_loss: 0.48682\n",
      "Validation loss decreased (0.496056 --> 0.486822).  Saving model ...\n",
      "[ 13/100] train_loss: 0.43901 valid_loss: 0.48107\n",
      "Validation loss decreased (0.486822 --> 0.481068).  Saving model ...\n",
      "[ 14/100] train_loss: 0.42936 valid_loss: 0.48094\n",
      "Validation loss decreased (0.481068 --> 0.480944).  Saving model ...\n",
      "[ 15/100] train_loss: 0.42419 valid_loss: 0.48371\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 16/100] train_loss: 0.41856 valid_loss: 0.48527\n",
      "EarlyStopping counter: 2 out of 20\n",
      "[ 17/100] train_loss: 0.41377 valid_loss: 0.48269\n",
      "EarlyStopping counter: 3 out of 20\n",
      "[ 18/100] train_loss: 0.41204 valid_loss: 0.48279\n",
      "EarlyStopping counter: 4 out of 20\n",
      "[ 19/100] train_loss: 0.41031 valid_loss: 0.48199\n",
      "EarlyStopping counter: 5 out of 20\n",
      "[ 20/100] train_loss: 0.40903 valid_loss: 0.48097\n",
      "EarlyStopping counter: 6 out of 20\n",
      "[ 21/100] train_loss: 0.40667 valid_loss: 0.48241\n",
      "EarlyStopping counter: 7 out of 20\n",
      "[ 22/100] train_loss: 0.40820 valid_loss: 0.47924\n",
      "Validation loss decreased (0.480944 --> 0.479241).  Saving model ...\n",
      "[ 23/100] train_loss: 0.40770 valid_loss: 0.48543\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 24/100] train_loss: 0.40734 valid_loss: 0.47821\n",
      "Validation loss decreased (0.479241 --> 0.478214).  Saving model ...\n",
      "[ 25/100] train_loss: 0.40596 valid_loss: 0.47238\n",
      "Validation loss decreased (0.478214 --> 0.472381).  Saving model ...\n",
      "[ 26/100] train_loss: 0.40728 valid_loss: 0.48879\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 27/100] train_loss: 0.40293 valid_loss: 0.48596\n",
      "EarlyStopping counter: 2 out of 20\n",
      "[ 28/100] train_loss: 0.40269 valid_loss: 0.48407\n",
      "EarlyStopping counter: 3 out of 20\n",
      "[ 29/100] train_loss: 0.40074 valid_loss: 0.48222\n",
      "EarlyStopping counter: 4 out of 20\n",
      "[ 30/100] train_loss: 0.40088 valid_loss: 0.47616\n",
      "EarlyStopping counter: 5 out of 20\n",
      "[ 31/100] train_loss: 0.40045 valid_loss: 0.46673\n",
      "Validation loss decreased (0.472381 --> 0.466726).  Saving model ...\n",
      "[ 32/100] train_loss: 0.40037 valid_loss: 0.47250\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 33/100] train_loss: 0.40116 valid_loss: 0.46820\n",
      "EarlyStopping counter: 2 out of 20\n",
      "[ 34/100] train_loss: 0.40200 valid_loss: 0.46375\n",
      "Validation loss decreased (0.466726 --> 0.463750).  Saving model ...\n",
      "[ 35/100] train_loss: 0.40388 valid_loss: 0.46707\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 36/100] train_loss: 0.40232 valid_loss: 0.48168\n",
      "EarlyStopping counter: 2 out of 20\n",
      "[ 37/100] train_loss: 0.40789 valid_loss: 0.46667\n",
      "EarlyStopping counter: 3 out of 20\n",
      "[ 38/100] train_loss: 0.40682 valid_loss: 0.46901\n",
      "EarlyStopping counter: 4 out of 20\n",
      "[ 39/100] train_loss: 0.40338 valid_loss: 0.49291\n",
      "EarlyStopping counter: 5 out of 20\n",
      "[ 40/100] train_loss: 0.40057 valid_loss: 0.48511\n",
      "EarlyStopping counter: 6 out of 20\n",
      "[ 41/100] train_loss: 0.40147 valid_loss: 0.48964\n",
      "EarlyStopping counter: 7 out of 20\n",
      "[ 42/100] train_loss: 0.40201 valid_loss: 0.47805\n",
      "EarlyStopping counter: 8 out of 20\n",
      "[ 43/100] train_loss: 0.40039 valid_loss: 0.46227\n",
      "Validation loss decreased (0.463750 --> 0.462273).  Saving model ...\n",
      "[ 44/100] train_loss: 0.39947 valid_loss: 0.45926\n",
      "Validation loss decreased (0.462273 --> 0.459257).  Saving model ...\n",
      "[ 45/100] train_loss: 0.39991 valid_loss: 0.47484\n",
      "EarlyStopping counter: 1 out of 20\n",
      "[ 46/100] train_loss: 0.39821 valid_loss: 0.47583\n",
      "EarlyStopping counter: 2 out of 20\n",
      "[ 47/100] train_loss: 0.39797 valid_loss: 0.47565\n",
      "EarlyStopping counter: 3 out of 20\n",
      "[ 48/100] train_loss: 0.39791 valid_loss: 0.47558\n",
      "EarlyStopping counter: 4 out of 20\n",
      "[ 49/100] train_loss: 0.39788 valid_loss: 0.47500\n",
      "EarlyStopping counter: 5 out of 20\n",
      "[ 50/100] train_loss: 0.39785 valid_loss: 0.47189\n",
      "EarlyStopping counter: 6 out of 20\n",
      "[ 51/100] train_loss: 0.39783 valid_loss: 0.47590\n",
      "EarlyStopping counter: 7 out of 20\n",
      "[ 52/100] train_loss: 0.39758 valid_loss: 0.46964\n",
      "EarlyStopping counter: 8 out of 20\n",
      "[ 53/100] train_loss: 0.39787 valid_loss: 0.47334\n",
      "EarlyStopping counter: 9 out of 20\n",
      "[ 54/100] train_loss: 0.39784 valid_loss: 0.47475\n",
      "EarlyStopping counter: 10 out of 20\n",
      "[ 55/100] train_loss: 0.39772 valid_loss: 0.47825\n",
      "EarlyStopping counter: 11 out of 20\n",
      "[ 56/100] train_loss: 0.39786 valid_loss: 0.47719\n",
      "EarlyStopping counter: 12 out of 20\n",
      "[ 57/100] train_loss: 0.39783 valid_loss: 0.47697\n",
      "EarlyStopping counter: 13 out of 20\n",
      "[ 58/100] train_loss: 0.39782 valid_loss: 0.47667\n",
      "EarlyStopping counter: 14 out of 20\n",
      "[ 59/100] train_loss: 0.39780 valid_loss: 0.47630\n",
      "EarlyStopping counter: 15 out of 20\n",
      "[ 60/100] train_loss: 0.39778 valid_loss: 0.47553\n",
      "EarlyStopping counter: 16 out of 20\n",
      "[ 61/100] train_loss: 0.39773 valid_loss: 0.46994\n",
      "EarlyStopping counter: 17 out of 20\n",
      "[ 62/100] train_loss: 0.39781 valid_loss: 0.47340\n",
      "EarlyStopping counter: 18 out of 20\n",
      "[ 63/100] train_loss: 0.39777 valid_loss: 0.47473\n",
      "EarlyStopping counter: 19 out of 20\n",
      "[ 64/100] train_loss: 0.39765 valid_loss: 0.47836\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "#patience = 20\n",
    "model, train_loss, valid_loss = train_model(model, \n",
    "                                            batch_size=20,epochs=100 , patience = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, batch_size):\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    model.eval() # prep model for evaluation\n",
    "\n",
    "    for data, target in loader_test:\n",
    "        if len(target.data) != batch_size:\n",
    "            break\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        print(target)\n",
    "        print(data)\n",
    "        print(pred)\n",
    "        for i in range(batch_size):\n",
    "            label = target.data[i]\n",
    "            #print('#############')\n",
    "            #print(, end=' ')\n",
    "            #print(target.data.view_as)\n",
    "            #print(loader_test.dataset)\n",
    "            #print(\"\\t\", label, \"\\t\" , target.data.view_as(pred))\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "        # calculate and print avg test loss\n",
    "        test_loss = test_loss/len(test)\n",
    "        print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                str(i), 100 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        #else:\n",
    "        #    print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #return target.data, label, correct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1])\n",
      "tensor([[-0.3199,  0.0274, -0.3871,  ...,  0.2444,  1.0000,  0.0000],\n",
      "        [ 0.7787, -0.1147,  0.5204,  ..., -0.1212, 21.0000,  1.0000],\n",
      "        [-0.1319, -0.1194, -0.3521,  ...,  0.2763,  1.0000,  1.0000],\n",
      "        ...,\n",
      "        [ 0.3970,  1.0212, -1.0551,  ...,  0.3575,  9.0000,  1.0000],\n",
      "        [-0.6048,  0.4381, -0.4709,  ...,  0.3205,  1.0000,  1.0000],\n",
      "        [ 0.1822,  0.0225, -0.5468,  ...,  0.6620,  6.0000,  0.0000]])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1])\n",
      "Test Loss: 0.036337\n",
      "\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "tensor([[-4.2895e-01, -4.8796e-01, -1.9639e-01,  ..., -8.2448e-02,\n",
      "          2.6000e+01,  1.0000e+00],\n",
      "        [ 2.1340e-01,  1.5919e-01, -9.6772e-01,  ...,  4.0688e-02,\n",
      "          7.0000e+00,  1.0000e+00],\n",
      "        [-4.6134e-01,  6.6106e-01, -5.1957e-01,  ...,  2.0994e-01,\n",
      "          1.0000e+00,  1.0000e+00],\n",
      "        ...,\n",
      "        [-9.0150e-01,  6.6820e-01, -5.2985e-01,  ...,  9.0929e-01,\n",
      "          8.0000e+00,  1.0000e+00],\n",
      "        [-2.4932e-01, -1.8350e-02, -7.7822e-01,  ...,  1.8491e-01,\n",
      "          1.0000e+00,  1.0000e+00],\n",
      "        [-3.1397e-01,  3.0610e-01, -4.4581e-01,  ...,  8.2171e-01,\n",
      "          2.0000e+00,  1.0000e+00]])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "Test Loss: 0.041551\n",
      "\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0])\n",
      "tensor([[ 0.0138, -0.1260, -0.3795,  ...,  0.2905,  2.0000,  1.0000],\n",
      "        [-0.7077,  0.1221, -0.5348,  ...,  0.1989,  1.0000,  1.0000],\n",
      "        [ 0.1823, -0.2515, -0.4129,  ..., -0.2549,  2.0000,  1.0000],\n",
      "        ...,\n",
      "        [-0.5820,  0.1428, -0.4893,  ...,  0.0389,  1.0000,  1.0000],\n",
      "        [-0.5245,  0.0530, -0.4747,  ...,  0.4314,  1.0000,  0.0000],\n",
      "        [-0.1141,  0.2070, -0.5586,  ...,  0.2514,  1.0000,  1.0000]])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0])\n",
      "Test Loss: 0.051237\n",
      "\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1])\n",
      "tensor([[-0.4951,  0.4183, -0.3902,  ..., -0.1665,  1.0000,  1.0000],\n",
      "        [ 0.5908,  0.0281, -0.4263,  ...,  0.9529,  7.0000,  1.0000],\n",
      "        [-0.5093,  0.1419, -0.8566,  ...,  0.3412,  1.0000,  1.0000],\n",
      "        ...,\n",
      "        [-0.8741,  0.3476, -0.2126,  ...,  0.1283,  2.0000,  1.0000],\n",
      "        [-0.3486,  0.2054, -0.9402,  ...,  0.2343,  1.0000,  1.0000],\n",
      "        [ 0.1031, -0.2843, -0.4130,  ...,  0.4551,  1.0000,  0.0000]])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      "Test Loss: 0.046531\n",
      "\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
      "tensor([[-1.0252,  0.1677, -0.4169,  ...,  0.2827,  3.0000,  0.0000],\n",
      "        [-0.2915,  0.5177, -0.2232,  ..., -0.3316,  1.0000,  1.0000],\n",
      "        [-0.3462,  0.4084, -0.0962,  ..., -0.1666,  1.0000,  1.0000],\n",
      "        ...,\n",
      "        [-0.2316,  0.2219, -0.7329,  ...,  0.3408,  1.0000,  1.0000],\n",
      "        [-0.1549,  0.8530, -0.0332,  ...,  0.3487,  1.0000,  1.0000],\n",
      "        [-0.8012,  0.0415, -0.9879,  ...,  0.4100,  2.0000,  1.0000]])\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0])\n",
      "Test Loss: 0.043173\n",
      "\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "tensor([[ 0.8398, -0.1540, -0.2432,  ...,  0.1264,  2.0000,  1.0000],\n",
      "        [-0.0314,  0.0714, -0.6161,  ...,  0.2148,  2.0000,  0.0000],\n",
      "        [-0.4101,  0.5565, -0.2457,  ...,  0.0160,  1.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.4177,  0.1210, -0.6563,  ..., -0.0687,  1.0000,  1.0000],\n",
      "        [-0.0647,  0.0430, -0.0465,  ...,  0.5814,  1.0000,  1.0000],\n",
      "        [-0.4608,  0.3342, -0.6400,  ...,  0.1533,  1.0000,  1.0000]])\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "Test Loss: 0.052891\n",
      "\n",
      "tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])\n",
      "tensor([[-0.1283,  0.2453, -0.6222,  ...,  0.2085,  1.0000,  1.0000],\n",
      "        [-0.5955,  0.0721, -0.7448,  ..., -0.1579,  1.0000,  0.0000],\n",
      "        [-0.4408,  0.5395, -0.0411,  ...,  0.3649,  3.0000,  1.0000],\n",
      "        ...,\n",
      "        [-0.1250,  0.3864, -0.1709,  ...,  0.5699, 15.0000,  1.0000],\n",
      "        [ 0.1820, -0.1500,  0.0573,  ...,  0.3336,  2.0000,  1.0000],\n",
      "        [ 0.1655, -0.0274, -0.3465,  ...,  0.1330,  1.0000,  1.0000]])\n",
      "tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0])\n",
      "Test Loss: 0.044393\n",
      "\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "tensor([[-2.9578e-01,  1.3256e+00, -3.4110e-01,  ..., -1.7923e-01,\n",
      "          7.0000e+00,  0.0000e+00],\n",
      "        [-1.9058e-01, -5.6104e-01, -7.3278e-01,  ...,  6.5075e-01,\n",
      "          4.0000e+00,  1.0000e+00],\n",
      "        [ 1.4803e-01,  5.0971e-01,  2.0687e-01,  ..., -3.3165e-01,\n",
      "          1.2000e+01,  1.0000e+00],\n",
      "        ...,\n",
      "        [ 2.4122e-01,  4.7575e-01, -7.4716e-02,  ..., -9.8846e-02,\n",
      "          1.0000e+00,  1.0000e+00],\n",
      "        [-1.4724e+00,  8.1107e-03, -8.8802e-01,  ...,  9.5123e-02,\n",
      "          5.0000e+00,  1.0000e+00],\n",
      "        [ 1.7400e-01,  6.5105e-01,  6.5254e-01,  ..., -8.6119e-02,\n",
      "          2.7000e+01,  1.0000e+00]])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Test Loss: 0.041557\n",
      "\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([[-0.0463, -0.0563, -0.3721,  ...,  0.3405,  1.0000,  1.0000],\n",
      "        [ 0.3590,  0.5522,  0.2941,  ..., -0.0579,  3.0000,  1.0000],\n",
      "        [-0.5810, -0.0145, -0.3220,  ...,  0.1010,  2.0000,  1.0000],\n",
      "        ...,\n",
      "        [ 0.1700,  0.5688,  0.1892,  ...,  0.2567,  1.0000,  1.0000],\n",
      "        [ 0.0368,  0.6395, -0.1685,  ...,  0.1504,  1.0000,  1.0000],\n",
      "        [-0.1600,  0.4340, -0.2627,  ..., -0.0647,  1.0000,  1.0000]])\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Test Loss: 0.041388\n",
      "\n",
      "tensor([1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0])\n",
      "tensor([[-0.1600,  0.4340, -0.2627,  ..., -0.0647,  1.0000,  1.0000],\n",
      "        [-1.1988,  0.1172, -0.5886,  ...,  0.3017,  6.0000,  1.0000],\n",
      "        [-0.0979,  0.3696, -0.2458,  ...,  0.7195,  1.0000,  1.0000],\n",
      "        ...,\n",
      "        [-0.1866, -0.1277, -0.0986,  ..., -0.0348,  1.0000,  1.0000],\n",
      "        [ 0.8297,  0.6360, -0.0658,  ...,  0.6415,  4.0000,  1.0000],\n",
      "        [-0.0720,  0.2056, -0.7503,  ..., -0.3448,  1.0000,  1.0000]])\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0])\n",
      "Test Loss: 0.041562\n",
      "\n",
      "Test Accuracy of     0: 98% (147/150)\n",
      "Test Accuracy of     1: 56% (28/50)\n",
      "\n",
      "Test Accuracy (Overall): 87% (175/200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "test_model(model, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 :  웨딩피치 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  년 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  진보 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  간호사 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  나이 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  해결 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  길 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  아줌마 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  기술 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  부모님 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  막상 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  물건 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  대학가 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  위로 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  문화 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  헬무새 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  한숨 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  돈 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  경제 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  좌좀 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  거 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  이해 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  혹시 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  부터 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  눈치 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  년놈 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  때 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  심 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  저런 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  도중 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  떡 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  성경 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  마찬가지 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  연애 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  님 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  헬조선 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  맞벌이 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  자기 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  뒷모습 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  차 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  일상 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  방법 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  정작 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  아예 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  ㅇㅈ \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  개극혐 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  안경 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  공무원 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  순간 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  등 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  제자리 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  모습 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  지랄 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  ㅈㄹ \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  현실 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  의외 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  걱정 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  좌빨 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  피지 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  여성 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  남 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  일반 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  해 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  평생 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  이부자리 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  신분 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  필리핀 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  계속 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  예민 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  집안일 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  시장 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  신경 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  눈길 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  매일 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  분위기 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  정상 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  샛기 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  존못 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  여사 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  입술 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  관리 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  아빠 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  공부 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  뭔가 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  경우 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  얼마나 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  대학 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  보빨 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  노답 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  씹선비 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  ㅈㄴ \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  취직 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  대의 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  환불 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  잘못 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  손 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  쥐뿔 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  ㅡㅡ \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  목솔 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  남혐 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  스스로 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  내용 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  어차피 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  지각 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  졸라 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  핸드폰 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  달라 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  글래머 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  연고 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  대통령 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  존나 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  장난 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  점수 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  보기 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  난쟁이 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  아우라 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  사업 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  보짓 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  밤새 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  취준생 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  존예 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  사건 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  아이폰 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  ㄹㅇ \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  왜곡 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  좆밥 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  쓰나미 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  승무원 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  친구 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  글 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  시발 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  합리화 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  ㅂㅅ \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  선배 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  뭐 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  섹스 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  폰 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  이기심 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  더 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  강매 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  이불 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  그때 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  마냥 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  인생 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  위축 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  피해 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  대처 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  방식 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  삼수 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  고양이 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  몸 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  사람 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  성매매 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  무엇 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  낫다 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  팩트 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  자고 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  시비 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  일단 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  인스타 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  중독 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  여우 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  도용 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  압살 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  살해 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  대신 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  들 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  녹음 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  내 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  휴학 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  가면 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  정리 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  성격 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  학교 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  구글링 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  질 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  빠순이 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  꿀팁 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  표 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  디엠 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  주의자 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  보고 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  통계 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  바지 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  글러 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  대갈 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  보빨충 \t실제 레이블 :  1 \t예측 레이블 : \n",
      "단어 :  일종 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  빚 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  바로 \t실제 레이블 :  0 \t예측 레이블 : \n",
      "단어 :  발악 \t실제 레이블 :  0 \t예측 레이블 : \n"
     ]
    }
   ],
   "source": [
    "TaggedWord = namedtuple('TaggedWord', 'word freq dict tag')\n",
    "tagged_words = [TaggedWord(w, f, d, c) for w,f,d,c \n",
    "                in test[[\"word\", \"frequency\", \"dict\", \"class\"]].values]\n",
    "for test in tagged_words:\n",
    "    if test.word in w2v_model: \n",
    "        print( \"단어 : \" ,test.word, \"\\t실제 레이블 : \" ,test.tag ,\"\\t예측 레이블 : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
